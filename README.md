# EMR--for-data-engineering

In this project I used Amazon Elastic Map Reduce (EMR) for processing large datasets using Apache Spark. It includes a Spark script for ETL (Extract, Transform, Load) operations, AWS command line instructions for setting up and managing the EMR cluster, and a dataset for testing and demonstration purposes.

## Project Structure

spark-etl.py: The main Spark script used for ETL operations.
commands.py: Scripts for AWS EMR cluster setup and management.
data/: Directory containing the dataset used in the ETL process.
